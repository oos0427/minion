{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\oos-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf_keras.utils.text_dataset_from_directory(r\"C:\\Work\\2024\\minion\\Workspace\\ml_basic\\data\\hide_data\\train\", batch_size=32)\n",
    "test_dataset = tf_keras.utils.text_dataset_from_directory(r\"C:\\Work\\2024\\minion\\Workspace\\ml_basic\\data\\hide_data\\test\", batch_size=32)\n",
    "#review_only_dataset = train_dataset.map(lambda x, y: x)\n",
    "review_only_dataset = train_dataset.map(lambda review, label: review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.batch_op._BatchDataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n",
      "**************************************************\n",
      "tf.Tensor(b\"Just saw this movie, and what a waste of time. The movie was predictable and slow. It's basically the Mormon bad news bears that play church sanctioned basketball. Rather than watching this movie, I should have had a root canal. The cameo performances were obviously driven by sponsorship / funding. This movie had potential due to the outrageous behavior that is exhibited by Mormons when they play church sanctioned basketball, however because it's rated PG, the true nature of the spectacle could not be transfered to film. The acting is horrible with the exception of Clint Howard and Fred Willard. Thurl Bailey's appearance in the film was completely unnecessary.\", shape=(), dtype=string)\n",
      "**************************************************\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    print(\"*\" * 50)\n",
    "    print(x[0])\n",
    "    print(\"*\" * 50)\n",
    "    print(y[0])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\oos-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\oos-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문장(단어집합) -> 숫자 집합 : encoding\n",
    "text_vectorizer = tf_keras.layers.TextVectorization(max_tokens=100000, #사전크기, 총단어갯수\n",
    "                                                    output_mode = \"int\",\n",
    "                                                    output_sequence_length = 300) #한 문장의 단어 갯수\n",
    "\n",
    "text_vectorizer.adapt(review_only_dataset) #단어사전 만들기 (주어진 데이터로 단어사전을 형성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 300)\n",
      "tf.Tensor(\n",
      "[[ 120   83    7 ...    0    0    0]\n",
      " [  45   11  671 ...    2 1983 6782]\n",
      " [1377  163  837 ...    0    0    0]\n",
      " ...\n",
      " [ 101  308   11 ...    0    0    0]\n",
      " [1162 3374  194 ...    0    0    0]\n",
      " [  10 1060   11 ...    0    0    0]], shape=(32, 300), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#변환기 테스트\n",
    "for x, y in train_dataset:\n",
    "    d = text_vectorizer(x) # X는 32개의 배치 x(32, 1) -> x(32, 300)\n",
    "    print(d.shape)\n",
    "    print(d)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = text_vectorizer.get_vocabulary()\n",
    "print(len(dictionary))\n",
    "dictionary[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 120   83    7   34  412 1857 1246  521   33  682]\n",
      "show people is an absolutely delightful silent directed by king vidor and starring marion davies and billy haines what gems both of them are in this charming comedy about a young girl peggy pepper whose acting is the talk of savannah trying to make it on the big screen though shes a success in comedy what she wants to do is make art so she moves up to high arts studio soon she becomes patricia pepoire and is too good for the likes of her friend [UNK] br many stars of the silent era have cameos in show people including davies herself without the curly hair and makeup im sure when people saw the film in 1928 they recognized everyone who appeared in the elaborate lunch scene sadly nowadays its not the case even for film buffs in one part of the film however she does meet charlie chaplin in another author elinor glyn is pointed out to her and vidor himself has a cameo at the end of the film other stars who pop up in show people are john gilbert douglas fairbanks william s hart leatrice joy bess flowers renee adoree rod laroque aileen pringle and many othersbr br davies was adorable and a lively comedienne its a shame william haines quit the movies he was cute and energetic deservedly an enormous star back in the daybr br show people is a simple story told in a witty way its also a look back at an exciting era in hollywoods history and contains performances by two wonderful stars "
     ]
    }
   ],
   "source": [
    "# 문자로 되돌리기\n",
    "d[0].shape\n",
    "print(d[0][:10].numpy())\n",
    "for t in d[0]:\n",
    "    if t != 0 :\n",
    "        print(dictionary[t], end= \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding 모델 만들기 : 단어(토큰을 벡터로 만드는 모델)\n",
    "input = tf_keras.layers.Input(shape=(None,))\n",
    "output = tf_keras.layers.Embedding(input_dim = 100000, output_dim = 100)(input)\n",
    "\n",
    "embedding_model = tf_keras.models.Model(inputs = input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in review_only_dataset:\n",
    "    #print(review)\n",
    "    vectorized_reviwe = text_vectorizer(review) # 단어 1 -> 숫자 1개\n",
    "    embedded_review = embedding_model(vectorized_reviwe) # 숫자 1개 -> 100개의 의미를 가진 숫자 1개\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 300]), TensorShape([32, 300, 100]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_reviwe.shape, embedded_review.shape # 배치,  (단어갯수, 의미) -> 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터의 모든 문자열을 숫자로 변경\n",
    "vectorized_train_dataset = train_dataset.map(lambda review, label: (text_vectorizer(review), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[19700  1664  1789 ...     0     0     0]\n",
      " [20567     7     4 ...     0     0     0]\n",
      " [   10   110   517 ...     0     0     0]\n",
      " ...\n",
      " [   11     7   353 ...     0     0     0]\n",
      " [    4  3659     6 ...   165  5350  1512]\n",
      " [  696     3 85646 ...     0     0     0]], shape=(32, 300), dtype=int64)\n",
      "tf.Tensor([0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#변환확인\n",
    "for x, y in vectorized_train_dataset:\n",
    "    print(x[:])\n",
    "    print(y[:])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 100)         10000000  \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                7488      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10007505 (38.18 MB)\n",
      "Trainable params: 10007505 (38.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델구성\n",
    "input = tf_keras.layers.Input(shape=(None,)) # 300 줘도 된다\n",
    "x = tf_keras.layers.Embedding(input_dim = 100000, output_dim = 100)(input) # (300, 100)\n",
    "x = tf_keras.layers.LSTM(units=16)(x)\n",
    "output = tf_keras.layers.Dense(units = 1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf_keras.models.Model(inputs = input, outputs = output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 124s 156ms/step - loss: 0.6686 - accuracy: 0.5705\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 119s 152ms/step - loss: 0.6121 - accuracy: 0.6759\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 0.6226 - accuracy: 0.6202\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 119s 152ms/step - loss: 0.5256 - accuracy: 0.7368\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 117s 150ms/step - loss: 0.4397 - accuracy: 0.8203\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 123s 157ms/step - loss: 0.4949 - accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 120s 153ms/step - loss: 0.5274 - accuracy: 0.7293\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 0.4156 - accuracy: 0.8314\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 0.3932 - accuracy: 0.8422\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 116s 149ms/step - loss: 0.3884 - accuracy: 0.8441\n"
     ]
    }
   ],
   "source": [
    "hisotry = model.fit(vectorized_train_dataset, epochs= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oos-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
